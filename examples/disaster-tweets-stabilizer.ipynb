{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63ff0819",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T09:46:30.830082Z",
     "iopub.status.busy": "2021-09-27T09:46:30.829140Z",
     "iopub.status.idle": "2021-09-27T09:48:55.478752Z",
     "shell.execute_reply": "2021-09-27T09:48:55.477965Z",
     "shell.execute_reply.started": "2021-09-27T07:10:02.104377Z"
    },
    "papermill": {
     "duration": 144.78824,
     "end_time": "2021-09-27T09:48:55.478978",
     "exception": false,
     "start_time": "2021-09-27T09:46:30.690738",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "dask-cudf 21.8.3 requires cupy-cuda114, which is not installed.\r\n",
      "cudf 21.8.3 requires cupy-cuda110, which is not installed.\r\n",
      "caip-notebooks-serverextension 1.0.0 requires google-cloud-bigquery-storage, which is not installed.\r\n",
      "torchvision 0.8.2+cu110 requires torch==1.7.1, but you have torch 1.9.0 which is incompatible.\r\n",
      "torchtext 0.8.1 requires torch==1.7.1, but you have torch 1.9.0 which is incompatible.\r\n",
      "torchaudio 0.7.2 requires torch==1.7.1, but you have torch 1.9.0 which is incompatible.\r\n",
      "pdpbox 0.2.1 requires matplotlib==3.1.1, but you have matplotlib 3.4.3 which is incompatible.\r\n",
      "hypertools 0.7.0 requires scikit-learn!=0.22,<0.24,>=0.19.1, but you have scikit-learn 0.24.2 which is incompatible.\r\n",
      "fastai 2.2.7 requires torch<1.8,>=1.7.0, but you have torch 1.9.0 which is incompatible.\r\n",
      "dask-cudf 21.8.3 requires dask<=2021.07.1,>=2021.6.0, but you have dask 2021.9.0 which is incompatible.\r\n",
      "dask-cudf 21.8.3 requires distributed<=2021.07.1,>=2021.6.0, but you have distributed 2021.9.0 which is incompatible.\r\n",
      "dask-cudf 21.8.3 requires pandas<1.3.0dev0,>=1.0, but you have pandas 1.3.1 which is incompatible.\r\n",
      "cudf 21.8.3 requires pandas<1.3.0dev0,>=1.0, but you have pandas 1.3.1 which is incompatible.\r\n",
      "allennlp 2.7.0 requires transformers<4.10,>=4.1, but you have transformers 4.10.0 which is incompatible.\u001b[0m\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -q stabilizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a7a8cb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T09:48:55.519700Z",
     "iopub.status.busy": "2021-09-27T09:48:55.519062Z",
     "iopub.status.idle": "2021-09-27T09:49:02.035181Z",
     "shell.execute_reply": "2021-09-27T09:49:02.034101Z",
     "shell.execute_reply.started": "2021-09-27T07:20:23.599516Z"
    },
    "papermill": {
     "duration": 6.54162,
     "end_time": "2021-09-27T09:49:02.035359",
     "exception": false,
     "start_time": "2021-09-27T09:48:55.493739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-27 09:48:57.887343: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from stabilizer.model import PoolerClassifier\n",
    "from stabilizer.llrd import get_optimizer_parameters_with_llrd\n",
    "from stabilizer.reinitialize import reinit_autoencoder_model\n",
    "from stabilizer.dataset import TextLabelDataset\n",
    "from stabilizer.trainer import train_step,evaluate_step\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from transformers import AutoModel,AutoTokenizer\n",
    "from sklearn.metrics import f1_score\n",
    "from transformers import get_scheduler\n",
    "from torch.optim import AdamW\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bbea95b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T09:49:02.071943Z",
     "iopub.status.busy": "2021-09-27T09:49:02.069729Z",
     "iopub.status.idle": "2021-09-27T09:49:02.072706Z",
     "shell.execute_reply": "2021-09-27T09:49:02.073215Z",
     "shell.execute_reply.started": "2021-09-27T07:20:28.823549Z"
    },
    "papermill": {
     "duration": 0.023611,
     "end_time": "2021-09-27T09:49:02.073361",
     "exception": false,
     "start_time": "2021-09-27T09:49:02.049750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONASSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77ef105d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T09:49:02.113687Z",
     "iopub.status.busy": "2021-09-27T09:49:02.112553Z",
     "iopub.status.idle": "2021-09-27T09:49:02.536091Z",
     "shell.execute_reply": "2021-09-27T09:49:02.535419Z",
     "shell.execute_reply.started": "2021-09-27T07:20:31.309831Z"
    },
    "papermill": {
     "duration": 0.448079,
     "end_time": "2021-09-27T09:49:02.536387",
     "exception": true,
     "start_time": "2021-09-27T09:49:02.088308",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24/129710571.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m }\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mseed_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seed'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'run_name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'seed_{config[\"seed\"]}_llrd_{config[\"llrd\"]}_reinit_{config[\"reinit\"]}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_24/1705247258.py\u001b[0m in \u001b[0;36mseed_everything\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mseed_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PYTHONASSEED'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'pretrained_model':'roberta-base',\n",
    "    'num_classes':1,\n",
    "    'batch_size':32,\n",
    "    'device_name':torch.device('cuda'),\n",
    "    'lr':1e-5,\n",
    "    'mutliplicative_lr':0.95,\n",
    "    'llrd':False,\n",
    "    'reinit':2,\n",
    "    'epochs':3,\n",
    "    'valid_every':15,\n",
    "    'scheduler':'linear',\n",
    "    'seed':1000\n",
    "}\n",
    "\n",
    "seed_everything(config['seed'])\n",
    "config['run_name'] = f'seed_{config[\"seed\"]}_llrd_{config[\"llrd\"]}_reinit_{config[\"reinit\"]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6316e5b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T07:20:34.40022Z",
     "iopub.status.busy": "2021-09-27T07:20:34.399604Z",
     "iopub.status.idle": "2021-09-27T07:20:45.894625Z",
     "shell.execute_reply": "2021-09-27T07:20:45.893651Z",
     "shell.execute_reply.started": "2021-09-27T07:20:34.400182Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "import os\n",
    "secret_value_0 = user_secrets.get_secret(\"WANDB_KEY\")\n",
    "os.environ[\"WANDB_API_KEY\"] = secret_value_0\n",
    "run = wandb.init(reinit=True, project=\"flowerpot_kaggle_disaster\", config=config)\n",
    "wandb.run.name = config['run_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35805e6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T07:20:45.899662Z",
     "iopub.status.busy": "2021-09-27T07:20:45.899198Z",
     "iopub.status.idle": "2021-09-27T07:20:45.99456Z",
     "shell.execute_reply": "2021-09-27T07:20:45.99378Z",
     "shell.execute_reply.started": "2021-09-27T07:20:45.899619Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../input/nlp-getting-started/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/nlp-getting-started/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445deaaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T07:20:46.000825Z",
     "iopub.status.busy": "2021-09-27T07:20:45.998807Z",
     "iopub.status.idle": "2021-09-27T07:20:46.03393Z",
     "shell.execute_reply": "2021-09-27T07:20:46.033253Z",
     "shell.execute_reply.started": "2021-09-27T07:20:46.000787Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"train dataset has {train_df.shape[0]} samples\")\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc9fa81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T07:20:46.040371Z",
     "iopub.status.busy": "2021-09-27T07:20:46.038407Z",
     "iopub.status.idle": "2021-09-27T07:20:46.064552Z",
     "shell.execute_reply": "2021-09-27T07:20:46.06369Z",
     "shell.execute_reply.started": "2021-09-27T07:20:46.040334Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train,valid = train_test_split(train_df,test_size=0.2,stratify=train_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a10480",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T07:20:46.070923Z",
     "iopub.status.busy": "2021-09-27T07:20:46.068631Z",
     "iopub.status.idle": "2021-09-27T07:20:46.081818Z",
     "shell.execute_reply": "2021-09-27T07:20:46.080783Z",
     "shell.execute_reply.started": "2021-09-27T07:20:46.070887Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepate data to create dataset\n",
    "train_tweets = train_df['text'].tolist()\n",
    "valid_tweets = train_df['text'].tolist()\n",
    "train_targets = torch.from_numpy(train_df['target'].to_numpy().reshape(-1, 1)).type(torch.float32)\n",
    "valid_targets = torch.from_numpy(train_df['target'].to_numpy().reshape(-1, 1)).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c15635",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T07:20:46.090211Z",
     "iopub.status.busy": "2021-09-27T07:20:46.087395Z",
     "iopub.status.idle": "2021-09-27T07:20:46.098858Z",
     "shell.execute_reply": "2021-09-27T07:20:46.097786Z",
     "shell.execute_reply.started": "2021-09-27T07:20:46.090162Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Dataset and DataLoader\n",
    "train_dataset = TextLabelDataset(text_excerpts=train_tweets, labels=train_targets)\n",
    "valid_dataset = TextLabelDataset(text_excerpts=valid_tweets, labels=valid_targets)\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "valid_dataloader = DataLoader(dataset=valid_dataset, batch_size=config['batch_size'], shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c99ea3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T07:20:46.107595Z",
     "iopub.status.busy": "2021-09-27T07:20:46.104697Z",
     "iopub.status.idle": "2021-09-27T07:20:46.11443Z",
     "shell.execute_reply": "2021-09-27T07:20:46.11349Z",
     "shell.execute_reply.started": "2021-09-27T07:20:46.107554Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "metric = f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba48142",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T07:20:46.122399Z",
     "iopub.status.busy": "2021-09-27T07:20:46.120121Z",
     "iopub.status.idle": "2021-09-27T07:20:46.151613Z",
     "shell.execute_reply": "2021-09-27T07:20:46.15077Z",
     "shell.execute_reply.started": "2021-09-27T07:20:46.122364Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_eval(train_dataloader,valid_dataloader):\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(config['pretrained_model'])\n",
    "    transformer = AutoModel.from_pretrained(config['pretrained_model'])\n",
    "    model = PoolerClassifier(transformer=transformer,\n",
    "                             transformer_output_size=transformer.config.hidden_size,\n",
    "                             transformer_output_dropout_prob=transformer.config.hidden_dropout_prob,\n",
    "                             num_classes=config['num_classes']\n",
    "                        )\n",
    "    device = torch.device(config['device_name'])\n",
    "    _ = model.to(device)\n",
    "    \n",
    "    \n",
    "    if config['llrd']:\n",
    "        parameters = get_optimizer_parameters_with_llrd(model,config['lr'],config['multiplicative_lr'])\n",
    "        \n",
    "    else:\n",
    "        no_decay = ['bias','layerNorm.weight']\n",
    "        parameters = [{'params':[p for n,p in model.named_parameters() if not any(k in n for k in no_decay)],\n",
    "                     'weight_decay':0.01,'lr':config['lr']},\n",
    "                      {'params':[p for n,p in model.named_parameters() if any(k in n for k in no_decay)],\n",
    "                     'weight_decay':0.00,'lr':config['lr']}]\n",
    "        \n",
    "    if config['reinit']:\n",
    "        model = reinit_autoencoder_model(model,config['reinit'])\n",
    "        \n",
    "    optimizer = AdamW(parameters)\n",
    "\n",
    "    num_training_steps = config['epochs'] * len(train_dataloader)\n",
    "    scheduler = get_scheduler(name=config['scheduler'],num_training_steps=num_training_steps,\n",
    "                              num_warmup_steps=int(0.1*num_training_steps),optimizer=optimizer)\n",
    "    num_iter=0\n",
    "    for epoch in range(config['epochs']):\n",
    "        train_f1,train_loss = 0.0,0.0\n",
    "        for batch in train_dataloader:\n",
    "            inputs = tokenizer(batch['text_excerpt'],padding=True, truncation=True,return_tensors='pt').to(config['device_name'])\n",
    "            targets = batch['label'].to(config['device_name'])\n",
    "            train_outputs = train_step(model=model, inputs=inputs, targets=targets, loss_fn=loss_fn, optimizer=optimizer,\n",
    "                                        scheduler=scheduler)\n",
    "            #train_f1 += metric(targets.detach().cpu().numpy(),train_outputs['predictions'].detach().cpu().numpy())\n",
    "            train_loss += train_outputs['loss']\n",
    "            if num_iter % config['valid_every'] == 0:\n",
    "                valid_f1,valid_loss = 0.0,0.0\n",
    "                for valid_batch in  valid_dataloader:\n",
    "                    inputs = tokenizer(valid_batch['text_excerpt'],padding=True, truncation=True,return_tensors='pt').to(config['device_name'])\n",
    "                    targets = valid_batch['label'].to(config['device_name'])\n",
    "                    valid_outputs = evaluate_step(model=model, inputs=inputs, targets=targets, loss_fn=loss_fn)\n",
    "                    predictions = (nn.Sigmoid()(valid_outputs['predictions'])).detach().cpu().numpy()\n",
    "                    \n",
    "                    valid_f1 += metric(targets.detach().cpu().numpy(),np.round(predictions),average='micro')\n",
    "                    valid_loss += valid_outputs['loss']\n",
    "                print(\"validation f1 score\",valid_f1/len(valid_dataloader))\n",
    "                print(\"validation loss\",valid_loss.item()/len(valid_dataloader))\n",
    "                wandb.log({'valid_loss':valid_loss.item()/len(valid_dataloader)},step=num_iter)\n",
    "                wandb.log({'valid_f1_score':valid_f1/len(valid_dataloader)},step=num_iter)\n",
    "            num_iter+=1\n",
    "\n",
    "            \n",
    "        print(f\"Train epoch {epoch} loss {train_loss.item()/len(train_dataloader)}\")\n",
    "        #print(f\"Train epoch {epoch} f1 score {train_f1/len(train_dataloader)}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41c3112",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T07:20:46.160515Z",
     "iopub.status.busy": "2021-09-27T07:20:46.1574Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_and_eval(train_dataloader,valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d7ee74",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 162.769315,
   "end_time": "2021-09-27T09:49:05.713195",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-09-27T09:46:22.943880",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
