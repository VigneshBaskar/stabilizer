{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4711a347-ce50-4a05-a829-18ef64f17f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this with pip install stabilizer\n",
    "import sys\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6031bb52-3b5a-41ca-94c1-8adf03117872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "from stabilizer.model import PoolerClassifier\n",
    "from stabilizer.dataset import TextLabelDataset\n",
    "from stabilizer.trainer import train_step, evaluate_step\n",
    "\n",
    "from transformers import get_scheduler, AdamW, AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1836f0fe-1995-410e-83e3-c54061ce3aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cab9eb42-2a5f-43c9-ac47-dad2cfbb0184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_targets(targets):\n",
    "    targets = targets.type(torch.int)\n",
    "    targets = targets.cpu().detach().numpy().reshape(-1)\n",
    "    return targets\n",
    "\n",
    "\n",
    "def post_process_predictions(predictions):\n",
    "    predictions = torch.sigmoid(predictions)\n",
    "    predictions = (predictions >= 0.5).type(torch.int)\n",
    "    predictions = predictions.cpu().detach().numpy().reshape(-1)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def compute_matthews_corrcoef(targets, predictions):\n",
    "    if len(np.unique(predictions)) > 1 and len(np.unique(targets)) > 1:\n",
    "        score = matthews_corrcoef(y_true=targets, y_pred=predictions)\n",
    "    else:\n",
    "        score = 0.0\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fac70052-c951-47cb-8bb7-8aeb07d34bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'train_data_path': '../data/glue/cola/train.jsonl',\n",
    "          'valid_data_path': '../data/glue/cola/valid.jsonl',\n",
    "          'batch_size': 32,\n",
    "          'pretrained_tokenizer_name_or_path': '../models/bert-base-uncased/',\n",
    "          'pretrained_model_name_or_path': '../models/bert-base-uncased/',\n",
    "          'device_name': 'cpu',\n",
    "          'dropout_prob': 0.1,\n",
    "          'num_classes': 1,\n",
    "          'lr': 2e-5,\n",
    "          'num_epochs': 3,\n",
    "          'validate_every_n_iteration': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb4e29f2-94f4-4f2f-b00c-de359c9797cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read training data\n",
    "train_data = pd.read_json(path_or_buf=config['train_data_path'], lines=True).set_index('idx')\n",
    "valid_data = pd.read_json(path_or_buf=config['valid_data_path'], lines=True).set_index('idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3f58b6b-4a23-4da3-854c-23815f42a3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a small snippet and Give a small explanation of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3972aa0f-3dbb-46c0-b90b-d958a2b10530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepate data to create dataset\n",
    "train_text_excerpts = train_data['text'].tolist()\n",
    "valid_text_excerpts = valid_data['text'].tolist()\n",
    "train_labels = torch.from_numpy(train_data['label'].to_numpy().reshape(-1, 1)).type(torch.float32)\n",
    "valid_labels = torch.from_numpy(valid_data['label'].to_numpy().reshape(-1, 1)).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f232b62-0368-445b-a987-48636baf082d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset and DataLoader\n",
    "train_dataset = TextLabelDataset(text_excerpts=train_text_excerpts, labels=train_labels)\n",
    "valid_dataset = TextLabelDataset(text_excerpts=valid_text_excerpts, labels=valid_labels)\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "valid_dataloader = DataLoader(dataset=valid_dataset, batch_size=config['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92fe18da-411a-4b4c-8cfb-01a1afa070ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(config['pretrained_tokenizer_name_or_path'])\n",
    "transformer = AutoModel.from_pretrained(pretrained_model_name_or_path=config['pretrained_model_name_or_path'],\n",
    "                                        hidden_dropout_prob=config['dropout_prob'],\n",
    "                                        attention_probs_dropout_prob=config['dropout_prob'])\n",
    "model = PoolerClassifier(transformer=transformer,\n",
    "                         transformer_output_size=transformer.config.hidden_size,\n",
    "                         transformer_output_dropout_prob=config['dropout_prob'],\n",
    "                         num_classes=config['num_classes'])\n",
    "device = torch.device(config['device_name'])\n",
    "_ = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e5c40d6-11c8-463d-a9b7-494b8ba573e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Create optimizer and scheduler\n",
    "model_parameters = model.parameters()\n",
    "optimizer = AdamW(params=model_parameters, lr=config['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7498e99d-979a-4467-b0bf-ade36bd39535",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/18/2021 13:58:04 - INFO - __main__ - Number of training steps: 804\n",
      "09/18/2021 13:58:04 - INFO - __main__ - Number of warmup steps: 80\n"
     ]
    }
   ],
   "source": [
    "num_training_steps = config['num_epochs'] * len(train_dataloader)\n",
    "num_warmup_steps = num_training_steps // 10\n",
    "logger.info(f'Number of training steps: {num_training_steps}')\n",
    "logger.info(f'Number of warmup steps: {num_warmup_steps}')\n",
    "\n",
    "scheduler = get_scheduler(name='linear',\n",
    "                          optimizer=optimizer,\n",
    "                          num_warmup_steps=num_warmup_steps,\n",
    "                          num_training_steps=num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90803ea3-fb0f-449b-938e-c010bdca46e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/18/2021 13:58:07 - INFO - __main__ - Iteration num: 0, Train loss: 0.8618794083595276\n",
      "09/18/2021 13:58:07 - INFO - __main__ - Iteration num: 0, Valid loss: 0.8374536633491516, Valid score: 0.0\n",
      "09/18/2021 13:58:13 - INFO - __main__ - Iteration num: 10, Train loss: 0.8465286493301392\n",
      "09/18/2021 13:58:13 - INFO - __main__ - Iteration num: 10, Valid loss: 0.812882125377655, Valid score: 0.022538632076706366\n",
      "09/18/2021 13:58:18 - INFO - __main__ - Iteration num: 20, Train loss: 0.7404846549034119\n",
      "09/18/2021 13:58:18 - INFO - __main__ - Iteration num: 20, Valid loss: 0.7380532026290894, Valid score: -0.020862608741005987\n",
      "09/18/2021 13:58:24 - INFO - __main__ - Iteration num: 30, Train loss: 0.648025631904602\n",
      "09/18/2021 13:58:24 - INFO - __main__ - Iteration num: 30, Valid loss: 0.6546173095703125, Valid score: -0.008820066505818383\n",
      "09/18/2021 13:58:29 - INFO - __main__ - Iteration num: 40, Train loss: 0.616409182548523\n",
      "09/18/2021 13:58:29 - INFO - __main__ - Iteration num: 40, Valid loss: 0.6468297243118286, Valid score: 0.0\n",
      "09/18/2021 13:58:35 - INFO - __main__ - Iteration num: 50, Train loss: 0.570499062538147\n",
      "09/18/2021 13:58:35 - INFO - __main__ - Iteration num: 50, Valid loss: 0.6573325991630554, Valid score: 0.0\n",
      "09/18/2021 13:58:41 - INFO - __main__ - Iteration num: 60, Train loss: 0.6461646556854248\n",
      "09/18/2021 13:58:41 - INFO - __main__ - Iteration num: 60, Valid loss: 0.6672601103782654, Valid score: 0.0\n",
      "09/18/2021 13:58:46 - INFO - __main__ - Iteration num: 70, Train loss: 0.6792887449264526\n",
      "09/18/2021 13:58:46 - INFO - __main__ - Iteration num: 70, Valid loss: 0.6625571846961975, Valid score: 0.0\n",
      "09/18/2021 13:58:52 - INFO - __main__ - Iteration num: 80, Train loss: 0.565446138381958\n",
      "09/18/2021 13:58:52 - INFO - __main__ - Iteration num: 80, Valid loss: 0.6489656567573547, Valid score: 0.0\n",
      "09/18/2021 13:58:58 - INFO - __main__ - Iteration num: 90, Train loss: 0.49698084592819214\n",
      "09/18/2021 13:58:58 - INFO - __main__ - Iteration num: 90, Valid loss: 0.6586999297142029, Valid score: 0.0\n",
      "09/18/2021 13:59:03 - INFO - __main__ - Iteration num: 100, Train loss: 0.5304003357887268\n",
      "09/18/2021 13:59:03 - INFO - __main__ - Iteration num: 100, Valid loss: 0.7118439674377441, Valid score: 0.006752295307176412\n",
      "09/18/2021 13:59:09 - INFO - __main__ - Iteration num: 110, Train loss: 0.4021459221839905\n",
      "09/18/2021 13:59:09 - INFO - __main__ - Iteration num: 110, Valid loss: 0.7574684023857117, Valid score: -0.0039735156456879766\n",
      "09/18/2021 13:59:15 - INFO - __main__ - Iteration num: 120, Train loss: 0.5526667237281799\n",
      "09/18/2021 13:59:15 - INFO - __main__ - Iteration num: 120, Valid loss: 0.738198459148407, Valid score: -0.015101572217628386\n",
      "09/18/2021 13:59:21 - INFO - __main__ - Iteration num: 130, Train loss: 0.5570167303085327\n",
      "09/18/2021 13:59:21 - INFO - __main__ - Iteration num: 130, Valid loss: 0.7815893888473511, Valid score: 0.005763061442986974\n",
      "09/18/2021 13:59:26 - INFO - __main__ - Iteration num: 140, Train loss: 0.4170573651790619\n",
      "09/18/2021 13:59:26 - INFO - __main__ - Iteration num: 140, Valid loss: 0.8038036227226257, Valid score: 0.01208225445393382\n",
      "09/18/2021 13:59:32 - INFO - __main__ - Iteration num: 150, Train loss: 0.4580405354499817\n",
      "09/18/2021 13:59:32 - INFO - __main__ - Iteration num: 150, Valid loss: 0.8131482601165771, Valid score: 0.02148706137590439\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1298/739207393.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mvalid_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                 \u001b[0mbatch_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_excerpt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                 \u001b[0mbatch_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mvalid_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/stabilizer/lib/python3.7/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1764\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1765\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1766\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Method `{func.__name__}` requires PyTorch.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/stabilizer/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0;31m# into a HalfTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_is_torch_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Attempting to cast a BatchEncoding to type {str(device)}. This is not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/stabilizer/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0;31m# into a HalfTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_is_torch_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Attempting to cast a BatchEncoding to type {str(device)}. This is not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iteration_num = 0\n",
    "for epoch in range(config['num_epochs']):\n",
    "    for batch in train_dataloader:\n",
    "        batch_inputs = tokenizer(text=batch['text_excerpt'], padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "        batch_targets = batch['label'].to(device)\n",
    "        train_outputs = train_step(model=model, inputs=batch_inputs, targets=batch_targets, loss_fn=loss_fn, optimizer=optimizer, scheduler=scheduler)\n",
    "        if iteration_num % config['validate_every_n_iteration'] == 0:\n",
    "            valid_targets, valid_predictions = [], []\n",
    "            for batch in valid_dataloader:\n",
    "                batch_inputs = tokenizer(text=batch['text_excerpt'], padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "                batch_targets = batch['label'].to(device)\n",
    "                valid_outputs = evaluate_step(model=model, inputs=batch_inputs, targets=batch_targets, loss_fn=loss_fn)\n",
    "                valid_targets.extend(valid_outputs['targets'])\n",
    "                valid_predictions.extend(valid_outputs['predictions'])\n",
    "            valid_targets = torch.vstack(valid_targets)\n",
    "            valid_predictions = torch.vstack(valid_predictions)\n",
    "            valid_loss = loss_fn(valid_predictions, valid_targets)\n",
    "            valid_targets = post_process_targets(valid_targets)\n",
    "            valid_predictions = post_process_predictions(valid_predictions)\n",
    "            valid_score = compute_matthews_corrcoef(targets=valid_targets, predictions=valid_predictions)\n",
    "            logger.info(f\"Iteration num: {iteration_num}, Train loss: {train_outputs['loss']}\")\n",
    "            logger.info(f\"Iteration num: {iteration_num}, Valid loss: {valid_loss}, Valid score: {valid_score}\")\n",
    "        iteration_num += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stabilizer",
   "language": "python",
   "name": "stabilizer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
